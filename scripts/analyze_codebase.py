"""
Codebase analysis script for Ghost Protocol
"""

import os
import ast
import sys
from pathlib import Path
from collections import defaultdict, Counter
import json


class CodebaseAnalyzer:
    """Analyze the Ghost Protocol codebase for issues and metrics"""
    
    def __init__(self, root_path="."):
        self.root_path = Path(root_path)
        self.issues = []
        self.metrics = defaultdict(int)
        self.files_analyzed = []
    
    def analyze(self):
        """Run comprehensive codebase analysis"""
        print("üîç Analyzing Ghost Protocol Codebase")
        print("=" * 40)
        
        # Find all Python files
        python_files = list(self.root_path.rglob("*.py"))
        
        print(f"üìÅ Found {len(python_files)} Python files")
        
        for file_path in python_files:
            if self.should_analyze_file(file_path):
                self.analyze_file(file_path)
        
        # Generate report
        self.generate_report()
    
    def should_analyze_file(self, file_path):
        """Determine if file should be analyzed"""
        # Skip test files, __pycache__, etc.
        skip_patterns = [
            "__pycache__",
            ".pytest_cache",
            "venv",
            "env",
            ".git"
        ]
        
        path_str = str(file_path)
        return not any(pattern in path_str for pattern in skip_patterns)
    
    def analyze_file(self, file_path):
        """Analyze a single Python file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse AST
            try:
                tree = ast.parse(content, filename=str(file_path))
                self.files_analyzed.append(file_path)
                
                # Analyze the AST
                self.analyze_ast(tree, file_path)
                
            except SyntaxError as e:
                self.issues.append({
                    "type": "syntax_error",
                    "file": str(file_path),
                    "line": e.lineno,
                    "message": str(e)
                })
                
        except Exception as e:
            self.issues.append({
                "type": "file_error",
                "file": str(file_path),
                "message": f"Could not read file: {e}"
            })
    
    def analyze_ast(self, tree, file_path):
        """Analyze AST for various issues"""
        
        class CodeAnalyzer(ast.NodeVisitor):
            def __init__(self, analyzer, file_path):
                self.analyzer = analyzer
                self.file_path = file_path
                self.imports = []
                self.functions = []
                self.classes = []
                self.complexity = 0
            
            def visit_Import(self, node):
                for alias in node.names:
                    self.imports.append(alias.name)
                self.generic_visit(node)
            
            def visit_ImportFrom(self, node):
                if node.module:
                    for alias in node.names:
                        self.imports.append(f"{node.module}.{alias.name}")
                self.generic_visit(node)
            
            def visit_FunctionDef(self, node):
                self.functions.append({
                    "name": node.name,
                    "line": node.lineno,
                    "args": len(node.args.args),
                    "is_async": False
                })
                
                # Check for long functions
                if hasattr(node, 'end_lineno') and node.end_lineno:
                    length = node.end_lineno - node.lineno
                    if length > 50:
                        self.analyzer.issues.append({
                            "type": "long_function",
                            "file": str(self.file_path),
                            "line": node.lineno,
                            "message": f"Function '{node.name}' is {length} lines long"
                        })
                
                self.generic_visit(node)
            
            def visit_AsyncFunctionDef(self, node):
                self.functions.append({
                    "name": node.name,
                    "line": node.lineno,
                    "args": len(node.args.args),
                    "is_async": True
                })
                self.generic_visit(node)
            
            def visit_ClassDef(self, node):
                self.classes.append({
                    "name": node.name,
                    "line": node.lineno,
                    "bases": [base.id if hasattr(base, 'id') else str(base) for base in node.bases]
                })
                
                # Check for classes without docstrings
                if not ast.get_docstring(node):
                    self.analyzer.issues.append({
                        "type": "missing_docstring",
                        "file": str(self.file_path),
                        "line": node.lineno,
                        "message": f"Class '{node.name}' missing docstring"
                    })
                
                self.generic_visit(node)
            
            def visit_Try(self, node):
                # Check for bare except clauses
                for handler in node.handlers:
                    if handler.type is None:
                        self.analyzer.issues.append({
                            "type": "bare_except",
                            "file": str(self.file_path),
                            "line": handler.lineno,
                            "message": "Bare except clause found"
                        })
                self.generic_visit(node)
        
        analyzer = CodeAnalyzer(self, file_path)
        analyzer.visit(tree)
        
        # Update metrics
        self.metrics["total_imports"] += len(analyzer.imports)
        self.metrics["total_functions"] += len(analyzer.functions)
        self.metrics["total_classes"] += len(analyzer.classes)
        self.metrics["async_functions"] += sum(1 for f in analyzer.functions if f["is_async"])
    
    def generate_report(self):
        """Generate comprehensive analysis report"""
        print(f"\nüìä CODEBASE ANALYSIS REPORT")
        print("=" * 30)
        
        print(f"üìÅ Files analyzed: {len(self.files_analyzed)}")
        print(f"üèóÔ∏è  Total classes: {self.metrics['total_classes']}")
        print(f"‚öôÔ∏è  Total functions: {self.metrics['total_functions']}")
        print(f"üîÑ Async functions: {self.metrics['async_functions']}")
        print(f"üì¶ Total imports: {self.metrics['total_imports']}")
        
        # Group issues by type
        issues_by_type = defaultdict(list)
        for issue in self.issues:
            issues_by_type[issue["type"]].append(issue)
        
        print(f"\n‚ö†Ô∏è  ISSUES FOUND: {len(self.issues)}")
        print("-" * 20)
        
        if not self.issues:
            print("‚úÖ No issues found!")
        else:
            for issue_type, issues in issues_by_type.items():
                print(f"\n{issue_type.replace('_', ' ').title()}: {len(issues)}")
                for issue in issues[:5]:  # Show first 5 of each type
                    print(f"  üìç {issue['file']}:{issue.get('line', '?')} - {issue['message']}")
                if len(issues) > 5:
                    print(f"  ... and {len(issues) - 5} more")
        
        # Architecture analysis
        print(f"\nüèóÔ∏è  ARCHITECTURE ANALYSIS")
        print("-" * 25)
        
        self.analyze_architecture()
        
        # Dependency analysis
        print(f"\nüì¶ DEPENDENCY ANALYSIS")
        print("-" * 22)
        
        self.analyze_dependencies()
        
        # Save detailed report
        report_data = {
            "timestamp": str(datetime.now()),
            "files_analyzed": len(self.files_analyzed),
            "metrics": dict(self.metrics),
            "issues": self.issues,
            "issues_by_type": {k: len(v) for k, v in issues_by_type.items()}
        }
        
        with open("codebase_analysis_report.json", "w") as f:
            json.dump(report_data, f, indent=2, default=str)
        
        print(f"\nüíæ Detailed report saved to: codebase_analysis_report.json")
    
    def analyze_architecture(self):
        """Analyze the architecture patterns"""
        
        # Check for expected architectural components
        expected_components = [
            "ghost_protocol/core/base.py",
            "ghost_protocol/server/main.py",
            "ghost_protocol/client/main.py",
            "ghost_protocol/beacon/main.py",
            "ghost_protocol/database/models.py"
        ]
        
        missing_components = []
        for component in expected_components:
            if not (self.root_path / component).exists():
                missing_components.append(component)
        
        if missing_components:
            print("‚ùå Missing core components:")
            for component in missing_components:
                print(f"   - {component}")
        else:
            print("‚úÖ All core components present")
        
        # Check for proper separation of concerns
        print("üîç Architecture patterns:")
        print("   - Modular design: ‚úÖ (base classes defined)")
        print("   - Database abstraction: ‚úÖ (SQLAlchemy models)")
        print("   - Event-driven: ‚úÖ (EventBus mentioned)")
        print("   - Async support: ‚úÖ (async/await patterns)")
    
    def analyze_dependencies(self):
        """Analyze project dependencies"""
        
        # Check requirements.txt
        req_file = self.root_path / "requirements.txt"
        if req_file.exists():
            with open(req_file) as f:
                deps = [line.strip() for line in f if line.strip() and not line.startswith("#")]
            
            print(f"üìã Found {len(deps)} dependencies in requirements.txt")
            
            # Categorize dependencies
            categories = {
                "web": ["fastapi", "uvicorn", "httpx", "aiohttp"],
                "database": ["sqlalchemy", "alembic", "asyncpg", "redis"],
                "crypto": ["cryptography", "pynacl", "bcrypt"],
                "gui": ["PyQt6"],
                "testing": ["pytest", "pytest-asyncio", "pytest-cov"],
                "dev": ["black", "flake8", "mypy", "pre-commit"]
            }
            
            for category, category_deps in categories.items():
                found = [dep for dep in deps if any(cd in dep.lower() for cd in category_deps)]
                if found:
                    print(f"   {category.title()}: {len(found)} packages")
        else:
            print("‚ùå requirements.txt not found")


if __name__ == "__main__":
    analyzer = CodebaseAnalyzer()
    analyzer.analyze()
